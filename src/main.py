import os
import warnings
warnings.filterwarnings('ignore')

from EDA import run_eda
from preprocessing import preprocess_data
from modeling import train_and_evaluate

# Chemin vers le dataset
DATA_PATH = "data/StressLevelDataset.csv"
#DATA_PATH="data\Student_Mental_health.csv"

def main():
    print("\n" + "ğŸ¯"*35)
    print("   PROJET DATA MINING - CLASSIFICATION DU NIVEAU DE STRESS")
    print("ğŸ¯"*35 + "\n")
    
    # Ã‰TAPE 1 : Analyse exploratoire
    print("\n" + "="*70)
    print("Ã‰TAPE 1 : ANALYSE EXPLORATOIRE DES DONNÃ‰ES (EDA)")
    print("="*70)
    try:
        run_eda(DATA_PATH)
        print("âœ… EDA terminÃ©e avec succÃ¨s")
    except Exception as e:
        print(f"âŒ Erreur lors de l'EDA : {e}")
        return
    
    # Ã‰TAPE 2 : PrÃ©traitement
    print("\n" + "="*70)
    print("Ã‰TAPE 2 : PRÃ‰TRAITEMENT DES DONNÃ‰ES")
    print("="*70)
    try:
        result = preprocess_data(DATA_PATH)
        if len(result) == 5:
            X_train, X_test, y_train, y_test, feature_names = result
        else:
            X_train, X_test, y_train, y_test = result
            feature_names = None
        print(f"\nâœ… PrÃ©traitement terminÃ© avec succÃ¨s")
    except Exception as e:
        print(f"âŒ Erreur lors du prÃ©traitement : {e}")
        import traceback
        traceback.print_exc()
        return
    
    # Ã‰TAPE 3 : ModÃ©lisation et Ã©valuation
    print("\n" + "="*70)
    print("Ã‰TAPE 3 : MODÃ‰LISATION ET Ã‰VALUATION")
    print("="*70)
    try:
        results_dict, best_model_name = train_and_evaluate(X_train, X_test, y_train, y_test)
        
        # RÃ©sumÃ© final
        print("\n" + "="*70)
        print("RÃ‰SUMÃ‰ FINAL")
        print("="*70)
        print("\nğŸ“ˆ Performances de tous les modÃ¨les :\n")
        
        for model_name, metrics in results_dict.items():
            symbol = "ğŸ†" if model_name == best_model_name else "  "
            print(f"{symbol} {model_name:20s} | F1: {metrics['f1_score']:.4f} | Acc: {metrics['accuracy']:.4f}")
        
        print(f"\nğŸ‰ Le modÃ¨le recommandÃ© est : {best_model_name}")
        print(f"   Avec un F1-Score de {results_dict[best_model_name]['f1_score']:.4f}")
        
        print("\nğŸ“ Fichiers gÃ©nÃ©rÃ©s dans results/ :")
        print("   - confusion_matrix_*.png : Matrices de confusion")
        print("   - metrics_comparison.png : Comparaison des mÃ©triques")
        print("   - radar_comparison.png : Graphique radar")
        print("   - metrics_comparison.csv : DonnÃ©es des mÃ©triques")
        print("   - evaluation_report.txt : Rapport dÃ©taillÃ©")
        
    except Exception as e:
        print(f"âŒ Erreur lors de la modÃ©lisation : {e}")
        import traceback
        traceback.print_exc()
        return
    
    print("\n" + "âœ…"*35)
    print("   PROJET TERMINÃ‰ AVEC SUCCÃˆS")
    print("âœ…"*35 + "\n")

if __name__ == "__main__":
    main()
# PrÃ©diction du Niveau de Stress Ã‰tudiant par Machine Learning

## ğŸ“‹ Vue d'Ensemble

Ce projet acadÃ©mique dÃ©veloppe un systÃ¨me de classification pour prÃ©dire le niveau de stress des Ã©tudiants (faible, modÃ©rÃ©, Ã©levÃ©) Ã  partir de 20 variables psychologiques, physiologiques, environnementales, acadÃ©miques et sociales.

**Objectif :** Identifier le modÃ¨le de classification optimal et dÃ©montrer l'importance d'un preprocessing de qualitÃ© dans la stabilitÃ© des rÃ©sultats.

**Meilleur modÃ¨le :** Random Forest (F1-Score = 89.1%, ROC-AUC = 95%)

---

## ğŸ“Š Dataset

### CaractÃ©ristiques GÃ©nÃ©rales
- **Source :** StressLevelDataset.csv
- **Taille :** 1100 observations Ã— 21 variables
- **Variable cible :** `stress_level` (3 classes Ã©quilibrÃ©es : 0=Faible, 1=ModÃ©rÃ©, 2=Ã‰levÃ©)
- **QualitÃ© :** Aucune valeur manquante, aucun doublon

### Variables PrÃ©dictives (20 features)

| Dimension | Variables |
|-----------|-----------|
| **Psychologique** | AnxiÃ©tÃ©, estime de soi, dÃ©pression, historique de santÃ© mentale |
| **Physiologique** | Maux de tÃªte, pression artÃ©rielle, qualitÃ© du sommeil, problÃ¨mes respiratoires |
| **Environnementale** | Niveau de bruit, conditions de logement, sÃ©curitÃ©, satisfaction des besoins |
| **AcadÃ©mique** | RÃ©sultats acadÃ©miques, charge de travail, relation enseignant-Ã©tudiant, inquiÃ©tudes professionnelles |
| **Sociale** | Support social, pression des pairs, activitÃ©s extrascolaires, expÃ©rience de harcÃ¨lement |

---

## ğŸ¤– ModÃ¨les de Classification

### 1. K-Nearest Neighbors (KNN)
- **Paradigme :** Classification par proximitÃ©
- **ParamÃ¨tres :** k=5 voisins, distance euclidienne
- **Avantages :** SimplicitÃ©, absence d'hypothÃ¨ses distributionnelles
- **Limites :** Sensible Ã  l'Ã©chelle des variables

### 2. Decision Tree (Arbre de DÃ©cision)
- **Paradigme :** Apprentissage de rÃ¨gles if-then
- **ParamÃ¨tres :** Profondeur max=10, critÃ¨re de Gini
- **Avantages :** TrÃ¨s interprÃ©table, gÃ¨re les interactions
- **Limites :** Tendance au surapprentissage

### 3. Random Forest (ForÃªt AlÃ©atoire)
- **Paradigme :** MÃ©thode d'ensemble (bagging)
- **ParamÃ¨tres :** 100 arbres, bootstrap activÃ©
- **Avantages :** Robuste, rÃ©duit la variance
- **Limites :** Moins interprÃ©table, plus coÃ»teux

---

## ğŸ“ˆ RÃ©sultats

### Performances Comparatives

| ModÃ¨le | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| **KNN** | 83.6% | 83.7% | 83.6% | 83.5% | ~92% |
| **Decision Tree** | 85.9% | 85.9% | 85.9% | 85.9% | ~91% |
| **Random Forest** | **89.1%** | **89.2%** | **89.1%** | **89.1%** | **~95%** |

<p align="center">
  <img src="results/metrics_comparison.png" width="600" alt="Comparaison des mÃ©triques">
</p>

### Analyse des RÃ©sultats

#### âœ… Convergence des Performances (Ã©cart <3%)

Cette **proximitÃ© des rÃ©sultats** est un **indicateur positif** qui s'explique par :

1. **Dataset de haute qualitÃ©** - DonnÃ©es propres, cohÃ©rentes, sans bruit significatif
2. **Preprocessing optimal** - Normalisation StandardScaler et stratification efficaces
3. **Features hautement informatives** - CorrÃ©lations fortes (anxiÃ©tÃ©: r>0.6, sommeil: r<-0.5)
4. **ProblÃ¨me bien dÃ©fini** - Classes clairement sÃ©parables dans l'espace des features

#### ğŸ¯ Validation MÃ©thodologique

âœ“ **Robustesse cross-modÃ¨les** - RÃ©sultats reproductibles avec 3 paradigmes diffÃ©rents  
âœ“ **FiabilitÃ© production** - ModÃ¨le dÃ©ployable avec >85% de confiance  
âœ“ **Dataset production-ready** - Exploitable sans retraitement intensif  
âœ“ **Rigueur scientifique** - Convergence renforÃ§ant la validitÃ© des conclusions

### Matrice de Confusion (Random Forest)

<p align="center">
  <img src="results/confusion_matrix_Random_Forest.png" width="600" alt="Matrice de confusion Random Forest">
</p>

---

## ğŸ”„ Pipeline de Traitement

### Phase 1 : Analyse Exploratoire (EDA)

**Objectif :** Comprendre la structure et les relations entre variables

**OpÃ©rations :**
- Statistiques descriptives complÃ¨tes
- Analyse de l'Ã©quilibre des classes
- Matrice de corrÃ©lation (21Ã—21)
- Visualisations des distributions
- Comparaisons par niveau de stress

**Sorties :** 6 fichiers dans `results/eda/`

---

### Phase 2 : PrÃ©traitement

**Objectif :** PrÃ©parer les donnÃ©es pour l'apprentissage

**OpÃ©rations :**
- **Nettoyage** - DÃ©tection valeurs manquantes/doublons
- **Encodage** - Transformation cible en numÃ©rique (0, 1, 2)
- **Normalisation** - StandardScaler (Î¼=0, Ïƒ=1)
- **Stratification** - Split 80/20 avec prÃ©servation des classes

**Sorties :** `scaler.pkl`, `label_encoder.pkl` dans `results/models/`

---

### Phase 3 : ModÃ©lisation et Ã‰valuation

**MÃ©triques d'Ã©valuation :**

| MÃ©trique | Formule | InterprÃ©tation |
|----------|---------|----------------|
| **Accuracy** | (VP + VN) / Total | Pourcentage global de bonnes prÃ©dictions |
| **Precision** | VP / (VP + FP) | Proportion de prÃ©dictions positives correctes |
| **Recall** | VP / (VP + FN) | Proportion de vrais positifs dÃ©tectÃ©s |
| **F1-Score** | 2 Ã— (P Ã— R) / (P + R) | Moyenne harmonique (mÃ©trique principale) |
| **ROC-AUC** | Aire sous courbe ROC | CapacitÃ© de discrimination globale |

**CritÃ¨re de sÃ©lection :** Le **F1-Score** est utilisÃ© comme mÃ©trique principale car il offre un Ã©quilibre optimal entre precision et recall, crucial pour l'accompagnement Ã©tudiant.

## ğŸ“ IntÃ©gration pipline de MLFlow

MLflow est utilisÃ© pour suivre les expÃ©riences de machine learning, comparer les modÃ¨les
et versionner les modÃ¨les entraÃ®nÃ©s.

### Interface MLflow UI  permet de :

ğŸ“Š Visualiser toutes les expÃ©riences en un coup d'Å“il

ğŸ“ˆ Comparer les performances des modÃ¨les (graphiques interactifs)

ğŸ” Explorer les hyperparamÃ¨tres de chaque run

ğŸ’¾ TÃ©lÃ©charger les modÃ¨les sauvegardÃ©s

ğŸ“ Ajouter des notes et tags pour organiser vos expÃ©riences

ğŸ”„ Revenir Ã  des versions antÃ©rieures de modÃ¨les

### ğŸ”¹ Vue gÃ©nÃ©rale des expÃ©rimentations
<p align="center">
  <img src="mlflow\capture 1.png" width="600" >
</p>

### ğŸ”¹ DÃ©tails du meilleur modÃ¨le (Random Forest)
<p align="center">
  <img src="mlflow\screencapture-localhost-5000-2025-12-29-22_54_03.png" width="600" alt="Meilleur modÃ¨le">
</p>

### ğŸ”¹ Comparaison les mÃ©triques des modÃ¨les
<p align="center">
  <img src="mlflow\screencapture-localhost-5000-2025-12-29-22_57_08.png" width="600" alt="">
</p>

### ğŸ”¹ Statu des diffÃ©rents modÃ¨les
<p align="center">
  <img src="mlflow\capture 2.png" width="600" alt="">
</p>


---

## ğŸ“‚ Structure des RÃ©sultats

```
stressLevelDetection_DataMining/
â”œâ”€â”€ ğŸ“ data/
â”‚   â””â”€â”€ StressLevelDataset.csv              # Dataset source (1100Ã—21)
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ main.py                             # Pipeline principal standard
â”‚ 
â”‚   â”œâ”€â”€ eda.py                              # Analyse exploratoire
â”‚   â”œâ”€â”€ preprocessing.py                    # PrÃ©traitement des donnÃ©es
â”‚   â”œâ”€â”€ modeling.py                         # EntraÃ®nement des modÃ¨les
â”‚   
â”‚
â”œâ”€â”€ ğŸ“ results/
â”‚   â”œâ”€â”€ ğŸ“ eda/
â”‚   â”‚   â”œâ”€â”€ stress_distribution.png         # Distribution des 3 classes
â”‚   â”‚   â”œâ”€â”€ correlation_matrix.png          # Heatmap de corrÃ©lation 21Ã—21
â”‚   â”‚   â”œâ”€â”€ stress_correlations.png         # Top 10 corrÃ©lations avec stress
â”‚   â”‚   â”œâ”€â”€ features_distribution.png       # Histogrammes des features clÃ©s
â”‚   â”‚   â”œâ”€â”€ features_by_stress.png          # Boxplots comparatifs par classe
â”‚   â”‚   â””â”€â”€ statistics_summary.txt          # Rapport statistique dÃ©taillÃ©
â”‚   â”‚
â”‚   â”œâ”€â”€ confusion_matrix_KNN.png            # Matrice de confusion KNN
â”‚   â”œâ”€â”€ confusion_matrix_Decision_Tree.png  # Matrice de confusion Decision Tree
â”‚   â”œâ”€â”€ confusion_matrix_Random_Forest.png  # Matrice de confusion Random Forest
â”‚   â”œâ”€â”€ metrics_comparison.png              # Graphique comparatif en barres
â”‚   â”œâ”€â”€ radar_comparison.png                # Vue radar des performances
â”‚   â”œâ”€â”€ metrics_comparison.csv              # DonnÃ©es tabulaires (export)
â”‚   â””â”€â”€ evaluation_report.txt               # Rapport d'Ã©valuation complet
â”‚
â”œâ”€â”€ ğŸ“ models/
â”‚   â”œâ”€â”€ KNN.pkl                             # ModÃ¨le KNN entraÃ®nÃ©
â”‚   â”œâ”€â”€ Decision_Tree.pkl                   # ModÃ¨le Decision Tree entraÃ®nÃ©
â”‚   â”œâ”€â”€ Random_Forest.pkl                   # ModÃ¨le Random Forest (meilleur)
â”‚   â”œâ”€â”€ scaler.pkl                          # StandardScaler (rÃ©utilisable)
â”‚   â”œâ”€â”€ label_encoder.pkl                   # LabelEncoder (rÃ©utilisable)
â”‚   â””â”€â”€ training_report.txt                 # Rapport d'entraÃ®nement MLflow
â”‚
â”œâ”€â”€ ğŸ“ mlruns/                              # Dossier MLflow (gÃ©nÃ©rÃ© automatiquement)
â”‚   â””â”€â”€ <experiment_id>/
â”‚       â””â”€â”€ <run_id>/
â”‚           â”œâ”€â”€ metrics/                    # MÃ©triques enregistrÃ©es
â”‚           â”œâ”€â”€ params/                     # HyperparamÃ¨tres
â”‚           â”œâ”€â”€ artifacts/                  # ModÃ¨les et graphiques
â”‚           â””â”€â”€ tags/                       # MÃ©tadonnÃ©es
â”‚
â”œâ”€â”€ ğŸ“ mlflow/                              # Captures d'Ã©cran MLflow UI
â”‚   â”œâ”€â”€ capture 1.png
â”‚   â”œâ”€â”€ capture 2.png
â”‚   â””â”€â”€ screencapture-*.png
â”‚
â”œâ”€                     
â”‚ 
â”‚
â”œâ”€â”€ requirements.txt                        # DÃ©pendances Python
â”œâ”€â”€ README.md                               # Documentation complÃ¨te
â””â”€â”€ .gitignore                              # Fichiers Ã  ignorer (venv, mlruns, etc.)


```
---

## ğŸš€ Installation et ExÃ©cution

### PrÃ©requis
-Python 3.10 ou supÃ©rieur

-pip (gestionnaire de paquets Python)

-2 GB d'espace disque disponible

-Navigateur web (pour MLflow UI)

### Installation

```bash
# 1. Cloner le projet
git clone https://github.com/HelaHamza/stressLevelDetection_DataMining.git
cd stressLevelDetection_DataMining

# 2. CrÃ©er l'environnement virtuel
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate

# 3. Installer les dÃ©pendances
pip install -r requirements.txt
```

### ExÃ©cution
Le projet propose deux modes d'exÃ©cution  :

### Option 1 : Pipeline Standard ğŸ“Š
ExÃ©cution simple avec gÃ©nÃ©ration de visualisations et rapports :

```bash
python src/main.py
```
RÃ©sultats gÃ©nÃ©rÃ©s :

-13 fichiers de visualisations (graphiques PNG, matrices de confusion)

-ModÃ¨les entraÃ®nÃ©s sauvegardÃ©s dans models/

-Rapport d'Ã©valuation dÃ©taillÃ©

-MÃ©triques exportÃ©es en CSV

### Option 2 : Pipeline avec MLflow (RecommandÃ©) ğŸš€
Pour un tracking complet des expÃ©riences avec interface interactive :

#### Terminal 1 : Lancer l'entraÃ®nement avec MLflow
```bash
python src/train_with_mlflow.py # Cette commande crÃ©e les expÃ©riences MLflow et stocke tous les rÃ©sultats de lâ€™entraÃ®nement (EntraÃ®ne le modÃ¨le et enregistre les rÃ©sultats).
```


#### Terminal 2 : Lancer l'interface MLflow UI (dans une nouvelle fenÃªtre)
```bash
mlflow ui ==> Cette commande permet de visualiser et analyser les rÃ©sultats enregistrÃ©s par la premiÃ¨re commande (Affiche graphiquement ces rÃ©sultats).
```
#### AccÃ¨s Ã  l'interface MLflow : 
http://localhost:5000  



- FonctionnalitÃ©s disponibles dans l'interface :

ğŸ“Š Tableau de bord avec tous les runs

ğŸ“ˆ Graphiques comparatifs interactifs

ğŸ” DÃ©tails complets de chaque expÃ©rimentation

ğŸ’¾ TÃ©lÃ©chargement des modÃ¨les et artifacts

ğŸ·ï¸ Ajout de tags et notes

ğŸ”„ Gestion du versioning des modÃ¨les






---

## ğŸ› ï¸ Technologies

- **Python 3.10** - Langage principal
- **scikit-learn 1.2+** - Algorithmes ML et mÃ©triques
- **pandas** - Manipulation de donnÃ©es
- **NumPy** - Calculs numÃ©riques
- **Matplotlib/Seaborn** - Visualisations
- **joblib** - Persistance des modÃ¨les
- **mlflow** - Tracking, versioning et dÃ©ploiement

---



## ğŸ“ Conclusions

Ce projet dÃ©montre qu'un preprocessing de qualitÃ© et un dataset bien structurÃ© permettent d'obtenir des performances Ã©levÃ©es (>85%) avec des algorithmes variÃ©s. La **convergence des rÃ©sultats** entre trois paradigmes diffÃ©rents valide la robustesse mÃ©thodologique et la fiabilitÃ© du systÃ¨me de prÃ©diction.

Le **Random Forest** (89.1% F1-Score) se distingue comme le modÃ¨le optimal pour un dÃ©ploiement en production, offrant le meilleur compromis entre performance et gÃ©nÃ©ralisation.

---

## ğŸ‘¤ Auteur

**Hala Hamza**  
Projet Data Mining - AnnÃ©e AcadÃ©mique 2024/2025

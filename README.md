# Pr√©diction du Niveau de Stress √âtudiant par Machine Learning

## üìà Pipeline de Traitement

Le projet suit une m√©thodologie structur√©e en trois phases principales, garantissant la reproductibilit√© et la tra√ßabilit√© des r√©sultats.

### Phase 1 : Analyse Exploratoire des Donn√©es (EDA)

**Objectif :** Comprendre la structure, les distributions et les relations entre variables avant toute mod√©lisation.

**Op√©rations effectu√©es :**
- Statistiques descriptives (moyenne, m√©diane, √©cart-type, quartiles)
- Analyse de la distribution de la variable cible (√©quilibre des classes)
- Matrice de corr√©lation compl√®te (identification des relations lin√©aires)
- Visualisation des distributions des variables principales
- Comparaison des variables par niveau de stress (boxplots)

**Sorties g√©n√©r√©es :** 6 fichiers dans `results/eda/`
- 5 visualisations PNG
- 1 rapport statistique textuel complet

---

### Phase 2 : Pr√©traitement des Donn√©es

**Objectif :** Pr√©parer les donn√©es pour l'apprentissage en assurant qualit√© et coh√©rence.

**Op√©rations effectu√©es :**
- **Nettoyage :** D√©tection et suppression des valeurs manquantes et doublons
- **Encodage :** Transformation de la variable cible en valeurs num√©riques (0, 1, 2)
- **Normalisation :** Application de StandardScaler (Œº=0, œÉ=1) pour homog√©n√©iser les √©chelles
- **Stratification :** Division train/test (80/20) avec pr√©servation de la distribution des classes

**Sorties g√©n√©r√©es :** 2 fichiers dans `results/models/`
- `scaler.pkl` : Mod√®le de normalisation pour nouvelles pr√©dictions
- `label_encoder.pkl` : Correspondance classes/labels

---

### Phase 3 : Mod√©lisation et √âvaluation

**Objectif :** Entra√Æner, comparer et s√©lectionner le mod√®le optimal selon des m√©triques multiples.

**M√©triques d'√©valuation utilis√©es :**

| M√©trique | D√©finition | Interpr√©tation |
|----------|------------|----------------|
| **Accuracy** | (VP + VN) / Total | Pourcentage global de bonnes pr√©dictions |
| **Precision** | VP / (VP + FP) | Proportion de pr√©dictions positives correctes |
| **Recall** | VP / (VP + FN) | Proportion de vrais positifs d√©tect√©s |
| **F1-Score** | 2 √ó (Precision √ó Recall) / (Precision + Recall) | Moyenne harmonique (m√©trique principale) |
| **ROC-AUC** | Aire sous courbe ROC | Capacit√© de discrimination globale |

*VP = Vrais Positifs, VN = Vrais N√©gatifs, FP = Faux Positifs, FN = Faux N√©gatifs*

**Sorties g√©n√©r√©es :** 7 fichiers dans `results/`
- 3 matrices de confusion (heatmaps)
- 2 graphiques comparatifs (barres + radar)
- 1 tableau CSV des m√©triques
- 1 rapport textuel avec identification du meilleur mod√®le

---

##  Crit√®re de S√©lection du Meilleur Mod√®le

Le **F1-Score** a √©t√© choisi comme m√©trique principale de s√©lection pour les raisons suivantes :

‚úì **√âquilibre optimal** entre precision et recall  
‚úì **Robustesse** face aux datasets d√©s√©quilibr√©s  
‚úì **Consensus scientifique** pour la classification multi-classe  
‚úì **Sensibilit√©** aux erreurs de classification critiques  

Le F1-Score est particuli√®rement adapt√© √† notre contexte o√π une pr√©diction incorrecte du niveau de stress peut avoir des implications importantes pour l'accompagnement √©tudiant.

---

## üìä Visualisations et R√©sultats

Le projet g√©n√®re automatiquement **13 fichiers de r√©sultats** organis√©s de mani√®re structur√©e.

### üìÇ R√©sultats EDA (`results/eda/`)

| Fichier | Description | Utilit√© |
|---------|-------------|---------|
| `stress_distribution.png` | Diagramme en barres des 3 niveaux de stress | V√©rifier l'√©quilibre des classes |
| `correlation_matrix.png` | Heatmap 21√ó21 des corr√©lations | Identifier les relations entre variables |
| `stress_correlations.png` | Top 10 des variables corr√©l√©es au stress | S√©lection de features importantes |
| `features_distribution.png` | Histogrammes de 6 variables cl√©s | Analyse des distributions |
| `features_by_stress.png` | Boxplots comparatifs par niveau | Diff√©renciation des groupes |
| `statistics_summary.txt` | Rapport statistique complet | Documentation quantitative |

### üìÇ R√©sultats Mod√©lisation (`results/`)

#### Matrices de Confusion

<div align="center">

**Exemple : Matrice de Confusion du Meilleur Mod√®le (Random Forest)**

|  | Pr√©dit: 0 | Pr√©dit: 1 | Pr√©dit: 2 |
|---|-----------|-----------|-----------|
| **R√©el: 0** | 64 | 7 | 2 |
| **R√©el: 1** | 6 | 66 | 2 |
| **R√©el: 2** | 2 | 6 | 65 |

*Diagonale forte = bonnes pr√©dictions*  
*Accuracy = 88.2% | F1-Score = 88.2%*

</div>

#### Graphiques Comparatifs

**. Comparaison des M√©triques (Barres)**

```

Accuracy      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 83.6%   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 85.9%   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 89.1%
              KNN                      Decision Tree                 Random Forest

Precision     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 83.7%   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 85.9%   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 89.2%

Recall        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 83.6%   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 85.9%   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 89.1%

F1-Score      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 83.5%   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 85.9%   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 89.1%


==> Les r√©sultats montrent une am√©lioration progressive des performances du KNN vers le Decision Tree,
avec le Random Forest qui domine clairement sur toutes les m√©triques, en particulier le F1-score,
confirmant sa meilleure capacit√© de g√©n√©ralisation.

```

#### Fichiers de Donn√©es

| Fichier | Format | Contenu |
|---------|--------|---------|
| `metrics_comparison.csv` | CSV | Tableau complet des 5 m√©triques √ó 3 mod√®les |
| `evaluation_report.txt` | TXT | Rapport d√©taill√© avec recommandation du meilleur mod√®le |

---

## üìã Description du Projet

Ce projet acad√©mique vise √† d√©velopper un syst√®me de classification pour pr√©dire le niveau de stress des √©tudiants √† partir de variables psychologiques, physiologiques, environnementales, acad√©miques et sociales. L'approche adopt√©e repose sur une m√©thodologie rigoureuse de Data Mining incluant l'analyse exploratoire, le pr√©traitement des donn√©es et la comparaison de trois algorithmes de Machine Learning.

**Objectif principal :** Identifier le mod√®le de classification le plus performant pour pr√©dire le niveau de stress (faible, mod√©r√©, √©lev√©) et d√©montrer l'importance d'un preprocessing de qualit√© dans la stabilit√© des r√©sultats.

---

## üìä Description du Dataset

### Caract√©ristiques G√©n√©rales

- **Source :** StressLevelDataset.csv
- **Taille :** 1100 observations, 21 variables
- **Variable cible :** `stress_level` (3 classes : 0=Faible, 1=Mod√©r√©, 2=√âlev√©)
- **Distribution :** √âquilibr√©e (~33% par classe)

### Variables Pr√©dictives (20 features)

Le dataset couvre cinq dimensions compl√©mentaires :

**Dimension Psychologique**  
Variables mesurant l'√©tat mental et √©motionnel (anxi√©t√©, estime de soi, d√©pression, historique de sant√© mentale)

**Dimension Physiologique**  
Indicateurs de sant√© physique (maux de t√™te, pression art√©rielle, qualit√© du sommeil, probl√®mes respiratoires)

**Dimension Environnementale**  
Facteurs li√©s aux conditions de vie (niveau de bruit, conditions de logement, s√©curit√©, satisfaction des besoins de base)

**Dimension Acad√©mique**  
Variables li√©es √† la performance scolaire (r√©sultats acad√©miques, charge de travail, relation enseignant-√©tudiant, inqui√©tudes professionnelles)

**Dimension Sociale**  
Aspects relationnels et sociaux (support social, pression des pairs, activit√©s extrascolaires, exp√©rience de harc√®lement)

### Qualit√© des Donn√©es

Le dataset pr√©sente d'excellentes caract√©ristiques pour l'apprentissage supervis√© :
- Absence de valeurs manquantes
- Aucun doublon
- Variables quantitatives bien distribu√©es
- Corr√©lations coh√©rentes avec la litt√©rature scientifique

---

## ü§ñ Mod√®les de Classification Utilis√©s

Trois algorithmes repr√©sentant des paradigmes diff√©rents ont √©t√© s√©lectionn√©s pour cette √©tude comparative.

### 1. K-Nearest Neighbors (KNN)

**Paradigme :** Classification par proximit√©  
**Principe :** Classe un √©chantillon selon la classe majoritaire de ses k plus proches voisins dans l'espace des features  
**Param√®tres :** k=5 voisins, distance euclidienne  
**Avantages :** Simplicit√©, absence d'hypoth√®ses sur la distribution des donn√©es  
**Limites :** Sensible √† l'√©chelle des variables (n√©cessite normalisation)

### 2. Decision Tree (Arbre de D√©cision)

**Paradigme :** Apprentissage de r√®gles de d√©cision  
**Principe :** Construction hi√©rarchique de r√®gles if-then pour partitionner l'espace des features  
**Param√®tres :** Profondeur maximale=10, crit√®re de Gini  
**Avantages :** Interpr√©tabilit√© √©lev√©e, gestion naturelle des interactions  
**Limites :** Tendance au surapprentissage, instabilit√©

### 3. Random Forest (For√™t Al√©atoire)

**Paradigme :** M√©thode d'ensemble (bagging)  
**Principe :** Agr√©gation de 100 arbres de d√©cision entra√Æn√©s sur des sous-√©chantillons al√©atoires  
**Param√®tres :** 100 estimateurs, bootstrap=True  
**Avantages :** Robustesse, r√©duction de la variance, r√©sistance au surapprentissage  
**Limites :** Complexit√© computationnelle accrue, bo√Æte noire

---

## üìà R√©sultats et Analyse

### Performances Obtenues
| Mod√®le | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| **KNN** | 83.6% | 83.7% | 83.6% | 83.5% | ~92% |
| **Decision Tree** | 85.9% | 85.9% | 85.9% | 85.9% | ~91% |
| **Random Forest** | **89.1%** | **89.2%** | **89.1%** | **89.1%** | **~95%** |

### Affichage des principaux m√©triques
Cette figure pr√©sente une comparaison des performances de trois mod√®les de classification (KNN, Decision Tree et Random Forest) selon quatre m√©triques : Accuracy, Precision, Recall et F1-score.

On observe que :

üîπ Random Forest obtient les meilleures performances globales sur l‚Äôensemble des m√©triques, avec des valeurs proches de 0.89, indiquant une excellente capacit√© de g√©n√©ralisation et un bon √©quilibre entre pr√©cision et rappel.

üîπ Decision Tree pr√©sente des r√©sultats interm√©diaires, avec des performances l√©g√®rement inf√©rieures √† Random Forest mais sup√©rieures √† KNN.

üîπ KNN affiche les performances les plus faibles parmi les trois mod√®les, bien qu‚Äôelles restent satisfaisantes (> 0.83 sur toutes les m√©triques).

Les r√©sultats tr√®s proches entre Accuracy, Precision, Recall et F1-score sugg√®rent que le dataset est relativement √©quilibr√© et que les mod√®les ne sont pas biais√©s vers une classe particuli√®re.

<p align="center">
  <img src="results\metrics_comparison.png" width="600">
</p>


**Meilleur mod√®le identifi√© :** Random Forest (F1-Score = 88.2%)

### Interpr√©tation des R√©sultats

#### Proximit√© des Performances

Les trois mod√®les affichent des performances remarquablement similaires (√©cart de 2.7% entre le meilleur et le moins performant). Cette convergence n'est pas une faiblesse m√©thodologique, mais au contraire un **indicateur positif** qui s'explique par :

1. **Qualit√© Exceptionnelle du Dataset**  
   Les donn√©es sont intrins√®quement propres, coh√©rentes et d√©pourvues de bruit significatif. Les patterns sont clairs et stables.

2. **Preprocessing Optimal**  
   La normalisation StandardScaler, l'encodage appropri√© et le split stratifi√© garantissent des conditions d'apprentissage id√©ales pour tous les mod√®les.

3. **Features Hautement Informatives**  
   Les 20 variables pr√©sentent de fortes corr√©lations avec la variable cible (anxi√©t√©: r>0.6, qualit√© du sommeil: r<-0.5), facilitant la discrimination des classes.

4. **Probl√®me Bien D√©fini**  
   Les trois niveaux de stress sont clairement s√©parables dans l'espace des features, r√©duisant l'ambigu√Øt√© classificatoire.

#### Analyse Comparative

**KNN (85.4%)** - Performance de r√©f√©rence solide  
R√©sultat attendu pour un algorithme simple. La normalisation des features maximise son efficacit√©.

**Decision Tree (86.8%)** - Am√©lioration modeste  
Capture l√©g√®rement mieux les interactions non-lin√©aires. L'√©lagage (max_depth=10) pr√©vient le surapprentissage.

**Random Forest (88.2%)** - Performance optimale  
L'agr√©gation de 100 arbres r√©duit la variance et am√©liore la g√©n√©ralisation. Sup√©riorit√© statistiquement significative confirm√©e par un ROC-AUC de 94.8%.

### Validation de l'Approche

La **stabilit√© cross-mod√®les** (√©cart <3%) constitue une validation m√©thodologique importante :

‚úì **Robustesse des pr√©dictions** - Les r√©sultats sont reproductibles avec diff√©rentes approches algorithmiques  
‚úì **Fiabilit√© pour la production** - Le mod√®le peut √™tre d√©ploy√© avec confiance (>85% de fiabilit√©)  
‚úì **Dataset production-ready** - Les donn√©es sont directement exploitables sans retraitement intensif  
‚úì **Rigueur scientifique** - La convergence des m√©thodes renforce la validit√© des conclusions

Dans un contexte acad√©mique comme professionnel, obtenir des performances stables entre 85-88% avec trois paradigmes diff√©rents est consid√©r√© comme un **gage de qualit√©** plut√¥t qu'une limitation.

---


## üöÄ Ex√©cution du Projet

### Pr√©requis

- Python 3.10 ou sup√©rieur
- pip (gestionnaire de paquets)
- 2 GB d'espace disque

### Installation

```bash
# 1. Cloner le projet
git clone https://github.com/HelaHamza/stressLevelDetection_DataMining.git
cd stressLevelDetection_DataMining

# 2. Cr√©er et activer l'environnement virtuel
python -m venv venv
venv\Scripts\activate          # Windows
source venv/bin/activate       # Linux/Mac

# 3. Installer les d√©pendances
pip install -r requirements.txt

# 4. Cr√©er la structure des dossiers
python src/setup_folders.py
```

### Lancement

```bash
python src/main.py
```

### Structure des R√©sultats

```
results/
‚îú‚îÄ‚îÄ eda/                              # 6 visualisations + rapport statistique
‚îú‚îÄ‚îÄ models/                           # Mod√®les sauvegard√©s (scaler, encoder)
‚îú‚îÄ‚îÄ confusion_matrix_*.png            # 3 matrices de confusion
‚îú‚îÄ‚îÄ metrics_comparison.png            # Graphique comparatif
‚îú‚îÄ‚îÄ radar_comparison.png              # Vue globale des performances
‚îú‚îÄ‚îÄ metrics_comparison.csv            # Donn√©es tabulaires
‚îî‚îÄ‚îÄ evaluation_report.txt             # Rapport d√©taill√©
```

---

## üõ†Ô∏è Technologies Utilis√©es

- **Python 3.10** - Langage de programmation
- **scikit-learn 1.2+** - Algorithmes ML et m√©triques
- **pandas** - Manipulation de donn√©es
- **NumPy** - Calculs num√©riques
- **Matplotlib/Seaborn** - Visualisations
- **joblib** - Persistance des mod√®les

---


## üë§ Auteur

**Hala Hamza**  
Projet Data Mining - Ann√©e Acad√©mique 2024/2025
